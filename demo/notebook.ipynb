{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98c421a-2eb2-4c3f-ae33-c032e45a4ce2",
   "metadata": {},
   "source": [
    "## Finetune your own Speech-to-Text Whisper model on the language of your choice on a GPU, for free!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81952bf78f81e416",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup GPU\n",
    "First, you'll need to enable GPUs for the notebook: Navigate to Editâ†’Notebook Settings Select T4 GPU from the Hardware Accelerator section Click Save and accept. Next, we'll confirm that we can connect to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "id": "5530e1c6-81cf-423f-8a6b-1d3842f4c3e1",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"GPU NOT available!\")\n",
    "else:\n",
    "    print(\"GPU is available!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3990c3b55f8e2ffc",
   "metadata": {},
   "source": [
    "### Setup and login to Mozilla Data Collective\n",
    "\n",
    "The dataset we use for finetuning is Mozilla's [Common Voice](https://commonvoice.mozilla.org/).\n",
    "\n",
    "***(Required)*** In order to download the Common Voice dataset you will need to first create an account at Mozilla Data Collective and then get an API key.\n",
    "1. Create a Mozilla Data Collective [account](https://datacollective.mozillafoundation.org/)\n",
    "2. Get your API key by following the instructions [here](https://datacollective.mozillafoundation.org/api-reference)\n",
    "3. Import your API key in this notebook by running the command below and using your key"
   ]
  },
  {
   "cell_type": "code",
   "id": "495fcf9c2076ed7e",
   "metadata": {},
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "os.environ[\"MDC_API_KEY\"] = getpass(\"Enter your Mozilla Data Collective API key: \")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d6b4db5e54d98073",
   "metadata": {},
   "source": [
    "***(Optional)*** If you want to track training and evaluation metrics of the finetuning and save your final model to use it and share it with others later, you will need a Hugging Face (HF) account.\n",
    "1. Create a HF [account](https://huggingface.co/join)\n",
    "2. Set up [personal access token](huggingface.co/settings/tokens)\n",
    "3. Login to hugging face in this notebook by running the command below and using your token\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3d1180a1814af08",
   "metadata": {},
   "source": [
    "!huggingface-cli login"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e46fb64-1b6c-4852-97cd-5134d1ebf3b3",
   "metadata": {},
   "source": [
    "### Download and install speech-to-text-finetune package"
   ]
  },
  {
   "cell_type": "code",
   "id": "e5efc6e4cb19631b",
   "metadata": {},
   "source": [
    "!git clone https://github.com/Mozilla-Data-Collective/speech-to-text-finetune.git"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "698e05e3c689f96b",
   "metadata": {},
   "source": [
    "%cd speech-to-text-finetune/"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f63e473-4309-44c6-9fb4-0c823ce7ee1e",
   "metadata": {},
   "source": [
    "!pip install --quiet -e ."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a772b02c5958fdd1",
   "metadata": {},
   "source": [
    "***IMPORTANT:*** After installing the package, you need to restart the kernel / session: \"Runtime -> Restart session\" and then run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "id": "dacce552-688b-41c5-b514-45e218e9c930",
   "metadata": {},
   "source": [
    "%cd speech-to-text-finetune/  # after restarting the session, you will need to change directory again"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da07095b78eba3c0",
   "metadata": {},
   "source": [
    "from speech_to_text_finetune.finetune_whisper import run_finetuning"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7c5f15df-4494-4902-b5a9-7fe22a228432",
   "metadata": {},
   "source": [
    "**NOTE**: Certain \"high-resource\" languages like English or French have really big datasets (+50GB) which might fill up your disk storage fast. Make sure you have enough storage available before choosing a Common Voice language and finetuning on it."
   ]
  },
  {
   "cell_type": "code",
   "id": "5ee21c1f-e255-4442-aaad-1be9b2e45e59",
   "metadata": {},
   "source": [
    "# @title Finetuning configuration and hyperparameter setting\n",
    "import yaml\n",
    "\n",
    "\n",
    "def save_to_yaml(filename=\"config.yaml\"):\n",
    "    with open(filename, \"w\") as file:\n",
    "        yaml.dump(cfg, file)\n",
    "\n",
    "\n",
    "model_id = \"openai/whisper-small\"  # @param [\"openai/whisper-tiny\", \"openai/whisper-small\", \"openai/whisper-medium\",\"openai/whisper-large-v3\"]\n",
    "dataset_id = \"cmflnuzw5hbe47u0fvrugjyb6\"  # Common Voice Scripted Speech 23.0 - Hindi  # @param {type: \"string\"}\n",
    "language = \"Hindi\"  # @param {type: \"string\"}\n",
    "repo_name = \"default\"  # @param {type: \"string\"}\n",
    "push_to_hub = True  # @param {type: 'boolean'}\n",
    "n_train_samples = -1  # @param {type: \"int\"}\n",
    "n_test_samples = -1  # @param {type: \"int\"}\n",
    "hub_private_repo = True  # @param {type: 'boolean'}\n",
    "max_steps = 50  # @param {type: \"slider\", min: 1, max: 3000, step: 10}\n",
    "per_device_train_batch_size = 32  # @param {type: \"slider\", min: 1, max: 300}\n",
    "gradient_accumulation_steps = 1  # @param {type: \"slider\", min: 1, max: 10}\n",
    "warmup_steps = 50  # @param {type: \"slider\", min: 0, max: 500}\n",
    "gradient_checkpointing = True  # @param {type: 'boolean'}\n",
    "fp16 = True  # @param {type: 'boolean'}\n",
    "per_device_eval_batch_size = 8  # @param {type: \"slider\", min: 1, max: 200}\n",
    "save_steps = 5  # @param {type: \"slider\", min: 1, max: 500}\n",
    "logging_steps = 5  # @param {type: \"slider\", min: 1, max: 500}\n",
    "load_best_model_at_end = True  # @param {type: 'boolean'}\n",
    "\n",
    "cfg = {\n",
    "    \"model_id\": model_id,\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"language\": language,\n",
    "    \"repo_name\": repo_name,\n",
    "    \"n_train_samples\": n_train_samples,\n",
    "    \"n_test_samples\": n_test_samples,\n",
    "    \"training_hp\": {\n",
    "        \"push_to_hub\": push_to_hub,\n",
    "        \"hub_private_repo\": hub_private_repo,\n",
    "        \"max_steps\": max_steps,\n",
    "        \"per_device_train_batch_size\": per_device_train_batch_size,\n",
    "        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"warmup_steps\": warmup_steps,\n",
    "        \"gradient_checkpointing\": gradient_checkpointing,\n",
    "        \"fp16\": fp16,\n",
    "        \"eval_strategy\": \"steps\",\n",
    "        \"per_device_eval_batch_size\": per_device_eval_batch_size,\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 225,\n",
    "        \"save_steps\": save_steps,\n",
    "        \"logging_steps\": logging_steps,\n",
    "        \"load_best_model_at_end\": load_best_model_at_end,\n",
    "        \"save_total_limit\": 1,\n",
    "        \"metric_for_best_model\": \"wer\",\n",
    "        \"greater_is_better\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "save_to_yaml()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "87cbdd59-4d67-45c9-9f59-d8d7100dd066",
   "metadata": {},
   "source": [
    "### Start finetuning job\n",
    "\n",
    "Note that this might take a while, anything from 10min to 10hours depending on your model choice and hyper-parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "73ef3bd5de291da3",
   "metadata": {},
   "source": [
    "run_finetuning(config_path=\"config.yaml\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47e7896b-41f8-45a4-ab85-65b95c1472ae",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
